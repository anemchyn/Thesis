%---------- Inleiding ---------------------------------------------------------


\section{Introduction}%
\label{sec:Introduction}


In recent years, food prices in Belgium have risen significantly, placing increasing financial pressure on students and other budget-conscious consumers. While several supermarket price comparison tools exist, they generally focus on presenting the lowest prices without considering practical limitations, such as the distance a consumer is willing to travel or the number of stores they can reasonably visit. As a result, these tools provide theoretically optimal solutions that are difficult to implement in real-world scenarios, particularly for students with limited mobility and tight schedules.
\par\vspace{0.8em}

Students frequently face challenges in identifying the most cost-effective shopping options. Limited budgets, combined with time and travel constraints, complicate efficient price comparisons across different supermarkets. Existing tools rarely incorporate these constraints, creating a gap between available price information and actionable, user-centered insights. This research addresses this gap by focusing on the development of a system tailored to the needs of students in Ghent.
\par\vspace{0.8em}

The main objective and the research question of this study is the design and development of a transparent and scalable system capable of automatically collecting, matching, and comparing supermarket prices in Belgium, while taking into account consumers' distance and limiting the amount of shops visited. 
\par\vspace{0.8em}

The result of this research is a prototype, implemented using Python and Django, that collects price data through web scraping from Belgian supermarket websites. Users of this prototype will be able to input a general shopping list and specify a maximum travel distance or a limit on the number of stores. The system will then calculate the most cost-effective combination of stores based on these constraints. The system will be evaluated using a predefined ''student shopping cart'' to compare the total cost of shopping at a single store versus the optimized multi-store recommendation generated by the system.
\par\vspace{0.8em}

This research contributes to the development of a realistic and accessible supermarket price comparison tools that integrate technical efficiency with consumer-centered constraints. By focusing on students' needs, the system aims to enhance price transparency and support informed, budget-conscious shopping decisions, offering practical insights that could inform future consumer-oriented applications. 
\par\vspace{0.8em}

%---------- Stand van zaken ---------------------------------------------------

\section{Literature Review}%
\label{sec:literature-review}


\subsection{Context: food prices and student pressure}

Recent Belgian indicators show persistent price pressure on food. According to Statbel's CPI' report the headline and the core inflation remain elevated throughout 2024-2025, with core inflation above 2\% in October 2025\autocite{2025a-s, 2025b-s}. Independent tracking by Testaankoop/Testachats likewise reports supermarket specific inflation around 4\% in 2025 \autocite{2025a-t,2025b-t}. Broader macro assessments \autocite{OCED} show the detailed impact of the inflation confirming the price pressure on the consumers.
Together, these sources substantiate the problem relevance for the price-sensitive groups such as students.

\subsection{Supermarket data: web scraping as a practical pipeline}

Because Belgian retailers rarely expose APIs for product/price feeds to the public, web scraping is a pragmatic way of obtaining structured price data from public pages. While \autocite{Logos2023} and \autocite{Brown2024} guide through ethical and methodological approach to web scraping, they do not propose specific technical implementation for cases where public APIs are not available. Building on their recommendations the following process is proposed in this paper: HTML retrieval using Requests library, parsing of the content using BeautifulSoup library, automating browser rendering using Selenium for JavaScript-dependent content, and storing the exact data in PostgreSQL database. The approach to Belgian specific market is inspired by Statbel \autocite{Loon2018}.

\subsection{Legal and Ethical considerations for scraping}

Scraping must respect terms of service, IP, and data-protection constraints. Comparative analyses of website Terms of Service show many platforms explicitly regulate ''robots/scrapers'', requiring researchers to weigh necessity, proportionality, and compliance mechanisms \autocite{Fiesler2020}. Recent overviews propose concrete checklists on legality, ethics, and institutional review, for example, documenting purpose, rate limits, storage, data sharing \autocite{Logos2023, Brown2024}. These frameworks guide the governance of the prototype.

\subsection{Product matching across retailers}

Price comparison requires aligning ''the same'' item across stores despite naming/pack size differences. Literature support a two-stage approach: 1. exact identifiers (e.g., EAN/GTIN) where available; 2. approximate/semantic matching using fuzzy similarity  (Levenshtein/TF-IDF/cosine) or ML embeddings for near-dublicate detection \autocite{Kerek2020, Ning2022}. These methods map directly from user's ''general-name'' item to store's specific unit requirement.

% For text extracted from receipts using OCR+fuzzy pipelines look at Rahmatsyah2025

\subsection{Decision support, trust, and constraints in grocery apps}

Trust is a critical factor influencing user's willingness to adopt digital grocery tools. Research by Chakraborty et al. \autocite{Chakraborty2024} highlights that in online grocery environments, user's trust is shaped by credibility and clarity of the information as well as the quality of system interaction. Building on this perspective, DeZao \autocite{DeZao2024} emphasizes trust in AI-powered systems. Systems that make their decision logic visible by showing data sources, timestamps are  perceived as more reliable and fair by users. Moreover, real-world constraints such as travel distance and ability to visit certain amount of stores affect the usefulness of such tool. Integrating these constraints into the tool can improve decision support criteria.


The literature supports a pipeline combining web scraping, reproducible matching (EAN-first + fuzzy/ML fallback), and transparent interfaces that expose source and recency, evaluated on precision/recall for matches and realistic student-centric constraints (distance, max stores) for cost outcomes. 


%---------- Methodologie ------------------------------------------------------
\section{Methodology}%
\label{sec:methodology}


This thesis focuses on the design and implementation of a functional prototype that automatically collects, matches, and compares supermarket prices in Belgium. The research process is divided into five main phases: system design, data collection, data processing and product matching, system implementation and evaluation.\par\vspace{0.8em}

\subsection{System Design}

In this phase, the system's architecture and data flow were defined to ensure modularity, scalability, and transparency. The architecture consists of three distinct layers. The first layer is called the data layer and manages the storage of product and price information in a PostgreSQL relational database. The second layer is the processing layer and handles web scraping, data cleaning, and product matching logic, implemented in Python. The third layer is the presentation layer, which provides a user interface through a Django web application, allowing users to input shopping lists and define constraints such as travel distance and the number of stores. These design choices were made to support future scalability and the integration of new supermarket and product data.
\par\vspace{0.8em}


\subsection{Data Collection}

The data collection phase focuses on gathering daily product and price information from selected Ghent supermarkets.
This is achieved using web scraping techniques, using Python libraries such as Requests, BeautifulSoup, and Selenium. Requests is used to send HTTP requests and retrieve the raw HTML content of web pages, giving access to publicly available information without a browser. BeautifulSoup is employed to parse and extract specific elements from the HTML content obtained through Requests. Lastly, Selenium is used for scraping dynamic websites that load data through JavaScript after initial page request.
\par\vspace{0.8em}

Each scraper retrieves product names and prices. All data is stored in structured tables within the PostgreSQL database, with additional metadata such as timestamps, data sources to maintain transparency and traceability. 

\subsection{Data Processing and Product Matching}

Since supermarkets use different product names and formats, the collected data requires pre-processing before comparison. This phase happens in a number of steps: data cleaning, normalization and product matching. The data cleaning  step includes the removal of duplicates and unit normalization (e.g. price per kg or per liter). The matching step implements string similarity algorithms, such as Levenshtein distance and cosine similarity on TF-IDF vectors, to match equivalent products across stores. The filtering step stores the closest product matches to ensure accuracy in comparisons. The result of this phase is a unified dataset where identical or similar products from different stores can be compared directly.

\subsection{System implementation}

The tool integrates following components into a single Django-based web application. Data Scraper runs scheduled scraping jobs and updates the database. Data Processor performs data cleaning and product matching. Comparison Engine calculates the most cost-effective store combinations based on user's constraints. User Interface allows users to input shopping lists and define parameters such as maximum distance and store count. The system is designed for local deployment during testing but can be extended for public use.

\subsection{Evaluation}

The evaluation phase assesses the practical usefulness of the system, using predefined student shopping carts that simulate realistic purchase scenarios. Each cart is analyzed through two perspectives: Single-store shopping (purchasing all items from one supermarket) and Optimized multi-store shopping (purchasing all items using the system's recommendation).

The results are compared to determine potential cost savings. Additionally, the technical performance can be collected, such as time for calculating the plan.
 
 
%---------- Verwachte resultaten ----------------------------------------------
\section{Expected results}%
\label{sec:expected-results}


The main expected outcome of this research is a functional prototype that demonstrates the feasibility of a system for collecting, matching and comparing product prices. This includes a working scraping module that collects price and data from multiple stores' websites, and a matching module for corresponding items across different shops with a high level of accuracy. After evaluation using predefined student carts, the prototype is expected to demonstrate measurable price difference when compared to shopping in a single supermarket. These results should confirm added value of the system in terms of affordability.
