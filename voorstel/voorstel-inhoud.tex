%---------- Inleiding ---------------------------------------------------------


\section{Introduction}%
\label{sec:Introduction}


In recent years, food prices in Belgium have risen significantly, placing increasing financial pressure on students and other budget-conscious consumers. While several supermarket price comparison tools exist, they generally focus on presenting the lowest prices without considering practical limitations, such as the distance a consumer is willing to travel or the number of stores they can reasonably visit. As a result, these tools provide theoretically optimal solutions that are difficult to implement in real-world scenarios, particularly for students with limited mobility and tight schedules.

Students frequently face challenges in identifying the most cost-effective shopping options. Limited budgets, combined with time and travel constraints, complicate efficient price comparisons across different supermarkets. Existing tools rarely incorporate these constraints, creating a gap between available price information and actionable, user-centered insights. This research addresses this gap by focusing on the development of a system tailored to the needs of students in Ghent.
\par\vspace{0.8em}

To develop such a system, the following main research question needs to be answered: How to design and develop a transparent and scalable system, capable of automatically collecting, matching, and comparing supermarket prices in Ghent, that takes into account consumers' distance and limits the amount of shops visited? 

To support answering this question and guide the research, an improved understanding of the target audience and the problem context is required. More specifically:
\begin{itemize}
    \item What factors currently influence students' consumption habits in Belgium?
    \item What kind of tools for price comparisons are available in Belgium, and what shortcomings do they have for students?
    \item What technical and practical challenges are there for collecting price data from Belgian supermarkets?
\end{itemize}

Furthermore, research into programmatic and architectural details of the candidate solution, and its success factors, needs to be conducted. More precisely:

\begin{itemize}
    \item How can supermarket price data be automatically collected and structured?
    \item What approaches can be used to match general product names to achieve accurate comparisons?
    \item How can the system calculate and recommend the most cost-effective combinations of stores within a user-defined distance and a store limit?
    \item How can the system architecture be designed to support scalability and transparency of the data?
    \item What criteria must the prototype meet in order to be considered a valid proof-of-concept? 
\end{itemize}
\par\vspace{0.8em}

The result of this research is a prototype, implemented using Python and Django, that collects price data through web scraping from Belgian supermarket websites. Users of this prototype will be able to input a general shopping list and specify a maximum travel distance or a limit on the number of stores. The system will then calculate the most cost-effective combination of stores based on these constraints. The system will be evaluated using a predefined ''student shopping cart'' to compare the total cost of shopping at a single store versus the optimized multi-store recommendation generated by the system.
\par\vspace{0.8em}

This research contributes to the development of a realistic and accessible supermarket price comparison tools that integrate technical efficiency with consumer-centered constraints. By focusing on students' needs, the system aims to enhance price transparency and support informed, budget-conscious shopping decisions, offering practical insights that could inform future consumer-oriented applications. 
\par\vspace{0.8em}

%---------- Stand van zaken ---------------------------------------------------

\section{Literature Review}%
\label{sec:literature-review}

\subsection{Context: food prices and student pressure}

Recent Belgian indicators show persistent price pressure on food. According to Statbel's CPI' report, the headline and core inflation remain elevated throughout 2024-2025, with core inflation above 2\% in October 2025\autocite{2025a-s, 2025b-s}. Independent tracking by Testaankoop/Testachats likewise reports supermarket specific inflation\newline around 4\% in 2025 \autocite{2025a-t,2025b-t}. Broader macro assessments \autocite{OCED} show the detailed impact of inflation, confirming price pressure on consumers.
Together, these sources substantiate the problem relevance for the price-sensitive groups such as students.

\subsection{Existing solutions}

There are several Belgian specific tools available to help consumers compare supermarket prices and select better products such as PingPrice \autocite{pingprice} and G4U \autocite{g4u}. However, both apps have their limitations. PingPrice compares products using barcodes, which prevents it from effectively comparing store-brand or generic products that lack standardized identifiers. As a result, many relevant items are excluded from comparisons.

G4U, on the other hand, offers extensive product and promotion information, but operates as a paid service, limiting its accessibility for students who already face financial constraints. Consequently, there is a need for a free and transparent alternative that allows users to compare generic product categories, rather than barcodes.



\subsection{Supermarket data: web scraping as a practical pipeline}

Because Belgian retailers rarely expose APIs for product/price feeds to the public, web scraping is a pragmatic way of obtaining structured price data from public pages. While \autocite{Logos2023} and \autocite{Brown2024} guide through ethical and methodological approach to web scraping, they do not propose specific technical implementation for cases where public APIs are not available. 


Building on their recommendations, the following process is proposed in this paper: 
HTML retrieval, parsing of the content, automated browser rendering for JavaScript-dependent content, and storing the price data. This approach to Belgian specific market is inspired by Statbel \autocite{Loon2018} paper.


\subsection{Legal and Ethical considerations for scraping}

Scraping must respect terms of service (ToS), IP, and data-protection constraints. Comparative analyses of website ToS show many platforms explicitly regulate ''robots/scrapers'', requiring researchers to weigh necessity, proportionality, and compliance mechanisms \autocite{Fiesler2020}. Recent overviews propose concrete checklists on legality, ethics, and institutional review: for example, documenting purpose, rate limits, storage, data sharing \autocite{Logos2023, Brown2024}. These frameworks guide the governance of the prototype.

\subsection{Product matching across retailers}

Price comparison requires aligning ''the same'' item across stores despite naming/pack size differences. Literature supports a two-stage approach: 1. exact identifiers (e.g., EAN/GTIN) where available; 2. approximate/semantic matching using fuzzy similarity  (Levehnstein/TF-IDF/cosine) or ML embeddings for near-duplicate detection \autocite{Kerek2020, Ning2022}. These methods map directly from user-supplied product name to store's specific unit.

% For text extracted from receipts using OCR+fuzzy pipelines look at Rahmatsyah2025

\subsection{Decision support, trust, and constraints in grocery apps}

Trust is a critical factor influencing user's willingness to adopt digital grocery tools. 
\autocite{Chakraborty2024} highlights the importance of information credibility, clarity and quality of interaction for building user's trust in online grocery environments. 
Building on this perspective, \autocite{DeZao2024} emphasizes trust in AI-powered systems. By showing their data sources and timestamps, these systems become more transparent and consequently are perceived as more reliable and fair by users.
Moreover, real-world constraints such as travel distance and ability to visit certain amount of stores affect the usefulness of such tools. Integration of these constraints expands and improves decision support criteria.

In summary, the literature supports a pipeline combining web scraping, reproducible matching (EAN-first + fuzzy/ML fallback), and transparent interfaces that expose source and recency, evaluated on precision/recall for matches and realistic student-centric constraints (e.g. distance, maximum amount of stores) for cost outcomes. 


%---------- Methodologie ------------------------------------------------------
\section{Methodology}%
\label{sec:methodology}


This thesis focuses on the design and implementation of a functional prototype that automatically collects, matches, and compares supermarket prices in Ghent. The research process is divided into five main phases: system design, data collection, data processing and product matching, system implementation and evaluation.\par\vspace{0.8em}

\subsection{System Design}

In the first phase, the system's architecture and data flow were defined to ensure modularity, scalability, and transparency. The architecture consists of three distinct layers. The first layer is called the data layer and manages the storage of product and price information in a PostgreSQL relational database. The second layer is the processing layer and handles web scraping, data cleaning, and product matching logic, implemented in Python. The third layer is the presentation layer, which provides a user interface through a Django web application, allowing users to input shopping lists and define constraints such as travel distance and the number of stores. These design choices were made to support future scalability and the integration of new supermarket and product data.
\par\vspace{0.8em}


\subsection{Data Collection}

The data collection phase focuses on gathering daily product and price information from selected Ghent supermarkets.
This is achieved using web scraping techniques, using Python libraries such as Requests, BeautifulSoup, and Selenium. Requests is used to send HTTP requests and retrieve the raw HTML content of web pages, giving access to publicly available information without a browser. BeautifulSoup is employed to parse and extract specific elements from the HTML content obtained through Requests. Lastly, Selenium is used for scraping dynamic websites that load data through JavaScript after initial page request.

Each scraper retrieves product names and prices. All data is stored along with additional metadata such as timestamps and data sources to maintain transparency and traceability. 

\subsection{Data Processing and Product Matching}

Since supermarkets use different product names and formats, the collected data requires preprocessing before comparison. This phase happens in a number of steps: data cleaning, normalization and product matching. The data cleaning step includes the removal of duplicates and unit normalization (e.g. price per kg or per liter). The matching step implements string similarity algorithms, such as Levehnstein distance and cosine similarity on TF-IDF vectors, to match equivalent products across stores. The filtering step stores the closest product matches to ensure accuracy in comparisons. The result of this phase is a unified dataset where identical or similar products from different stores can be compared directly.

\subsection{System implementation}

The tool integrates following components into a single Django-based web application. Data Scraper runs scheduled scraping jobs and updates the database. Data Processor performs data cleaning and product matching. Comparison Engine calculates the most cost-effective store combinations based on user's constraints. User Interface allows users to input shopping lists and define parameters such as maximum distance and store count. The system is designed for local deployment during testing but can be extended for public use.

\subsection{Evaluation}

The evaluation phase assesses the practical usefulness of the system, using predefined student shopping carts that simulate realistic purchase scenarios. Each cart is analyzed from two perspectives: Single-store shopping (purchasing all items in one supermarket) and Optimized multi-store shopping (purchasing all items using the system's recommendation).

Based on these results, the prototype can be considered a successful proof-of-concept if it is capable of producing cost reductions for Ghent students with various criteria, while maintaining transparency in its decision process. 
 
 
%---------- Verwachte resultaten ----------------------------------------------
\section{Expected results}%
\label{sec:expected-results}


The main expected outcome of this research is a functional prototype that demonstrates the feasibility of a system for collecting, matching and comparing product prices. This includes a working scraping module that collects price and data from multiple stores' websites, and a matching module for corresponding items across different shops with a high level of accuracy. After evaluation using predefined student carts, the prototype is expected to demonstrate measurable price difference when compared to shopping in a single supermarket. These results should confirm added value of the system in terms of affordability.
