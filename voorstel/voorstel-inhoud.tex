%---------- Inleiding ---------------------------------------------------------


\section{Introduction}%
\label{sec:Introduction}


In recent years, food prices in Belgium have risen significantly, placing increasing financial pressure on students and other budget-conscious consumers. While several supermarket price comparison tools exist, they generally focus on presenting the lowest prices without considering practical limitations, such as the distance a consumer is willing to travel or the number of stores they can reasonably visit. As a result, these tools provide theoretically optimal solutions that are difficult to implement in real-world scenarios, particularly for students with limited mobility and tight schedules.
\par\vspace{0.8em}

Students frequently face challenges in identifying the most cost-effective shopping options. Limited budgets, combined with time and travel constraints, complicate efficient price comparisons across different supermarkets. Existing tools rarely incorporate these constraints, creating a gap between available price information and actionable, user-centered insights. This research addresses this gap by focusing on the development of a system tailored to the needs of students in Ghent.
\par\vspace{0.8em}

The main objective and the research question of this study is the design and development of a transparent and scalable system capable of automatically collecting, matching, and comparing supermarket prices in Belgium, while taking into account consumers' distance and limiting the amount of shops visited. 
\par\vspace{0.8em}

The result of this research is a prototype, implemented using Python and Django, that collects price data through web scraping from Belgian supermarket websites. Users of this prototype will be able to input a general shopping list and specify a maximum travel distance or a limit on the number of stores. The system will then calculate the most cost-effective combination of stores based on these constraints. The system will be evaluated using a predefined ''student shopping cart'' to compare the total cost of shopping at a single store versus the optimized multi-store recommendation generated by the system.
\par\vspace{0.8em}

This research contributes to the development of a realistic and accessible supermarket price comparison tools that integrate technical efficiency with consumer-centered constraints. By focusing on students' needs, the system aims to enhance price transparency and support informed, budget-conscious shopping decisions, offering practical insights that could inform future consumer-oriented applications. 
\par\vspace{0.8em}

%---------- Stand van zaken ---------------------------------------------------

\section{Literature Review}%
\label{sec:literature-review}


\subsection{Context: food prices and student pressure}

Recent Belgian indicators show persistent price pressure on food. According to Statbel's CPI' report, the health-index inflation remains elevated throughout 2024-2025, with core inflation above 2\% \autocite{2025a-s, 2025b-s}. Independent tracking by Testaankoop/Testachats likewise reports supermarket specific inflation around 4\% year-over-year in 2025 \autocite{2025a-t,2025b-t}. 
% Broader macro assessments \autocite{OCED} frame the consumer impact and index methodology changes under consideration. 
Together, these sources substantiate the problem relevance for the price-sensitive groups such as students.

\subsection{Supermarket data: web scraping as a practical pipeline}

Because Belgian retailers rarely expose APIs for product/price feeds to the public, web scraping is a pragmatic way of obtaining structured price data from public pages. Technically, HTTP clients (e.g., Requests) fetch HTML, parsers (e.g. BeautifulSoup) extract fields, and browser automation (e.g. Selenium) renders JavaScript-dependent content, an approach widely documented in research and practice \autocite{Logos2023, Brown2024}. Scraping has been adopted in adjacent Belgian retail domains (real-estate, FMCG) to assemble large, timely datasets for analysis, such as UNECE case on Belgian's CPI use of web data; \autocite{Kerek2020}.

\subsection{Legal and Ethical considerations for scraping}

Scraping must respect terms of service, IP, and data-protection constraints. Comparative analyses of website ToS show many platforms explicitly regulate ''robots/scrapers'', requiring researchers to weigh necessity, proportionality, and compliance mechanisms \autocite{Fiesler2020}. Recent overviews propose concrete checklists on legality, ethics, and institutional review, for example, documenting purpose, rate limits, storage, data sharing, and honoring robots.txt \autocite{Logos2023, Brown2024}. These frameworks guide the governance you will include in your prototype (e.g., timestamps, source attribution, throttling).

\subsection{Product matching across retailers}

Price comparison requires aligning ''the same'' item across stores despite naming/pack size differences. Literature support a two-stage approach: 1. exact identifiers (e.g., EAN/GTIN) where available; 2. approximate/semantic matching using fuzzy similarity  (Levenshtein/TF-IDF/cosine) or ML embeddings for near-dublicate detection \autocite{Kerek2020, Ning2022}. For text extracted from receipts or noisy pages, OCR+fuzzy pipelines evaluated with precision/recall/F1 provide a practical baseline \autocite{Rahmatsyah2025}. These methods map directly to your ''general-name shopping list -> store SKUs' requirement.

\subsection{Decision support, trust, and constraints in grocery apps}

Beyond raw price, adoption depends on trust (source transparency, update timestamps) and real-life constrains (distance, number of stores). Research in online grocery contexts highlights that transparency and explainability improve perceived reliability and intention to use \autocite{Chakraborty2024}. Recommender-style approaches in grocery show multi-criteria trade-offs (e.g. product/pack/health), which you can adapt to incorporate distance and store-count as constraints in the optimization objective \autocite{Hafez2021}. The literature supports a pipeline combining complaint scraping, reproducible matching (EAN-first + fuzzy/ML fallback), and transparent interfaces that expose source and recency, evaluated on precision/recall for matches and realistic student-centric constraints (distance, max stores) for cost outcomes. 


%---------- Methodologie ------------------------------------------------------
\section{Methodology}%
\label{sec:methodology}


This thesis focuses on the design and implementation of a functional prototype that automatically collects, matches, and compares supermarket prices in Belgium. The research process is divided into five main phases: system design, data collection, data processing and product matching, system implementation and evaluation.\par\vspace{0.8em}

\subsection{System Design}

In this phase, the system's architecture and data flow were defined to ensure modularity, scalability, and transparency. The architecture consists of three distinct layers. The first layer is called the data layer and manages the storage of product and price information in a PostgreSQL relational database. The second layer is the processing layer and handles web scraping, data cleaning, and product matching logic, implemented in Python. The third layer is the presentation layer, which provides a user interface through a Django web application, allowing users to input shopping lists and define constraints such as travel distance and the number of stores. These design choices were made to support future scalability and the integration of new supermarket and product data.
\par\vspace{0.8em}


\subsection{Data Collection}

The data collection phase focuses on gathering daily product and price information from selected Ghent supermarkets.
This is achieved using web scraping techniques, using Python libraries such as Requests, BeautifulSoup, and Selenium. Requests is used to send HTTP requests and retrieve the raw HTML content of web pages, giving access to publicly available information without a browser. BeautifulSoup is employed to parse and extract specific elements from the HTML content obtained through Requests. Lastly, Selenium is used for scraping dynamic websites that load data through JavaScript after initial page request.
\par\vspace{0.8em}

Each scraper retrieves product names and prices. All data is stored in structured tables within the PostgreSQL database, with additional metadata such as timestamps, data sources to maintain transparency and traceability. 

\subsection{Data Processing and Product Matching}

Since supermarkets use different product names and formats, the collected data requires pre-processing before comparison. This phase happens in a number of steps: data cleaning, normalization and product matching. The data cleaning  step includes the removal of duplicates and unit normalization (e.g. price per kg or per liter). The matching step implements string similarity algorithms, such as Levenshtein distance and cosine similarity on TF-IDF vectors, to match equivalent products across stores. The filtering step stores the closest product matches to ensure accuracy in comparisons. The result of this phase is a unified dataset where identical or similar products from different stores can be compared directly.

\subsection{System implementation}

The tool integrates following components into a single Django-based web application. Data Scraper runs scheduled scraping jobs and updates the database. Data Processor performs data cleaning and product matching. Comparison Engine calculates the most cost-effective store combinations based on user's constraints. User Interface allows users to input shopping lists and define parameters such as maximum distance and store count. The system is designed for local deployment during testing but can be extended for public use.

\subsection{Evaluation}

The evaluation phase assesses the practical usefulness of the system, using predefined student shopping carts that simulate realistic purchase scenarios. Each cart is analyzed through two perspectives: Single-store shopping (purchasing all items from one supermarket) and Optimized multi-store shopping (purchasing all items using the system's recommendation).

The results are compared to determine potential cost savings. Additionally, the technical performance can be collected, such as time for calculating the plan.
 
 
%---------- Verwachte resultaten ----------------------------------------------
\section{Expected results}%
\label{sec:expected-results}


The main expected outcome of this research is a functional prototype that demonstrates the feasibility of a system for collecting, matching and comparing product prices. This includes a working scraping module that collects price and data from multiple stores' websites, and a matching module for corresponding items across different shops with a high level of accuracy. After evaluation using predefined student carts, the prototype is expected to demonstrate measurable price difference when compared to shopping in a single supermarket. These results should confirm added value of the system in terms of affordability.
